{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n...\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import statements\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "'''\n",
    "...\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path variables for data import\n",
    "path_org_data = './data/org_sets/'\n",
    "path_res_data = './data/resampled/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Set 1 Shape: (2240, 129)\n",
      "Feature Set 2 Shape: (2240, 153)\n"
     ]
    }
   ],
   "source": [
    "# read in feature_set1 & 2 of resampled data\n",
    "res_f1 = pd.read_pickle(filepath_or_buffer = path_res_data + 'featureSet1.pkl')\n",
    "res_f2 = pd.read_pickle(filepath_or_buffer = path_res_data + 'featureSet2.pkl')\n",
    "org_f1 = pd.read_pickle(filepath_or_buffer = path_org_data + 'featureSet1.pkl')\n",
    "org_f2 = pd.read_pickle(filepath_or_buffer = path_org_data + 'featureSet2.pkl')\n",
    "\n",
    "print('Feature Set 1 Shape: ' + str(res_f1.shape))\n",
    "print('Feature Set 2 Shape: ' + str(res_f2.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8540540540540541\n"
     ]
    }
   ],
   "source": [
    "# trail for fS2 resampled\n",
    "\n",
    "X = res_f2.iloc[:, :-1]\n",
    "y = res_f2.iloc[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7960526315789473\n"
     ]
    }
   ],
   "source": [
    "# trail for fS2 org\n",
    "\n",
    "X_org = org_f1.iloc[:, :-1]\n",
    "y_org = org_f1.iloc[:, -1]\n",
    "\n",
    "X_train_org, X_test_org, y_train_org, y_test_org = train_test_split(X_org, y_org, test_size=0.33, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "model.fit(X_train_org, y_train_org)\n",
    "\n",
    "print(model.score(X_test_org, y_test_org))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1 0.8432432432432433\n",
    "# f2 0.831081081081081 ??? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM Model training \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler_org = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "scaler_org.fit(X_org)\n",
    "X_scaled_org = scaler_org.transform(X_org)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.827 (0.017)\n",
      "Accuracy: 0.828 (0.017)\n"
     ]
    }
   ],
   "source": [
    "# CV SVM SMOTE\n",
    "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "clf = svm.SVC()\n",
    "\n",
    "scores = cross_val_score(clf, X_scaled, y, scoring='f1_weighted', cv=cv, n_jobs=-1)\n",
    "print('F1: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(clf, X_scaled, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.778 (0.033)\n",
      "Accuracy: 0.792 (0.030)\n"
     ]
    }
   ],
   "source": [
    "# CV SVM ORG\n",
    "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "clf = svm.SVC()\n",
    "\n",
    "scores = cross_val_score(clf, X_scaled_org, y_org, scoring='f1_weighted', cv=cv, n_jobs=-1)\n",
    "print('F1: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(clf, X_scaled_org, y_org, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.851 (0.024)\n",
      "Accuracy: 0.857 (0.023)\n"
     ]
    }
   ],
   "source": [
    "#CV Random Forest SMOTE\n",
    "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "scores = cross_val_score(clf, X, y, scoring='f1_weighted', cv=cv, n_jobs=-1)\n",
    "print('F1: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(clf, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.799 (0.017)\n",
      "Accuracy: 0.798 (0.023)\n"
     ]
    }
   ],
   "source": [
    "#CV Random Forest ORG\n",
    "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "scores = cross_val_score(clf, X_org, y_org, scoring='f1_weighted', cv=cv, n_jobs=-1)\n",
    "print('F1: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(clf, X_org, y_org, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.843 (0.005)\n",
      "Accuracy: 0.844 (0.004)\n"
     ]
    }
   ],
   "source": [
    "# CV MLP SMOTE\n",
    "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(1000, 50), random_state=1)\n",
    "\n",
    "scores = cross_val_score(clf, X_scaled, y, scoring='f1_weighted', cv=cv, n_jobs=-1)\n",
    "print('F1: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(clf, X_scaled, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.791 (0.009)\n",
      "Accuracy: 0.792 (0.009)\n"
     ]
    }
   ],
   "source": [
    "# CV MLP ORG\n",
    "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(1000, 50), random_state=1)\n",
    "\n",
    "scores = cross_val_score(clf, X_scaled_org, y_org, scoring='f1_weighted', cv=cv, n_jobs=-1)\n",
    "print('F1: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(clf, X_scaled_org, y_org, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.828 (0.017)\n",
      "Accuracy: 0.829 (0.017)\n"
     ]
    }
   ],
   "source": [
    "# CV Log Reg SMOTE\n",
    "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "clf = LogisticRegression(max_iter=2000)\n",
    "\n",
    "scores = cross_val_score(clf, X_scaled, y, scoring='f1_weighted', cv=cv, n_jobs=-1)\n",
    "print('F1: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(clf, X_scaled, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.775 (0.011)\n",
      "Accuracy: 0.777 (0.010)\n"
     ]
    }
   ],
   "source": [
    "# CV Log Reg ORG\n",
    "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "clf = LogisticRegression(max_iter=2000)\n",
    "\n",
    "scores = cross_val_score(clf, X_scaled_org, y_org, scoring='f1_weighted', cv=cv, n_jobs=-1)\n",
    "print('F1: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(clf, X_scaled_org, y_org, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.331 (0.061)\n",
      "Accuracy: 0.417 (0.050)\n"
     ]
    }
   ],
   "source": [
    "# CV AdaBoost SMOTE\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "clf = AdaBoostClassifier()\n",
    "\n",
    "scores = cross_val_score(clf, X, y, scoring='f1_weighted', cv=cv, n_jobs=-1)\n",
    "print('F1: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(clf, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.412 (0.066)\n",
      "Accuracy: 0.510 (0.046)\n"
     ]
    }
   ],
   "source": [
    "# CV AdaBoost ORG\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "clf = AdaBoostClassifier()\n",
    "\n",
    "scores = cross_val_score(clf, X_org, y_org, scoring='f1_weighted', cv=cv, n_jobs=-1)\n",
    "print('F1: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "scores = cross_val_score(clf, X_org, y_org, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mlp = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(1000, 50), random_state=1)\n",
    "mlp.fit(X_train, y_train)\n",
    "y_true = mlp.predict(X_test)\n",
    "print(accuracy_score(y_test, y_true))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logReg = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "y_true = logReg.predict(X_test)\n",
    "print(accuracy_score(y_test, y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "class_names = y.unique()\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "titles_options = [\n",
    "    (\"Confusion matrix, without normalization\", None),\n",
    "    (\"Normalized confusion matrix\", \"true\"),\n",
    "]\n",
    "for title, normalize in titles_options:\n",
    "    disp = ConfusionMatrixDisplay.from_estimator(\n",
    "        mlp,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        display_labels=class_names,\n",
    "        cmap=plt.cm.Blues,\n",
    "        normalize=normalize,\n",
    "    )\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)\n",
    "plt.rcParams['text.color'] = 'black'\n",
    "plt.rcParams['axes.labelcolor'] = 'black'\n",
    "plt.rcParams['xtick.color'] = 'black'\n",
    "plt.rcParams['ytick.color'] = 'black'\n",
    "plt.rcParams[\"figure.figsize\"]=(20,10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoost -> Decision Tree\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "classifier = AdaBoostClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_true = classifier.predict(X_test)\n",
    "print(accuracy_score(y_test, y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation 5 Fold -> Beste Metrik Normalized Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_confusion_matrix(cnf_matrix, classes, normalize=False, title='Confusion matrix'):\n",
    "    if normalize:\n",
    "        cnf_matrix = cnf_matrix.astype('float') / cnf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cnf_matrix, interpolation='nearest', cmap=plt.get_cmap('BuGn'))\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cnf_matrix.max() / 2.\n",
    "\n",
    "    for i, j in itertools.product(range(cnf_matrix.shape[0]), range(cnf_matrix.shape[1])):\n",
    "        plt.text(j, i, format(cnf_matrix[i, j], fmt), horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cnf_matrix[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "    return cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(data_x, data_y):\n",
    "    k_fold = KFold(5, shuffle=True, random_state=1)\n",
    "\n",
    "    predicted_targets = np.array([])\n",
    "    actual_targets = np.array([])\n",
    "\n",
    "    for train_ix, test_ix in k_fold.split(data_x):\n",
    "        train_x, train_y, test_x, test_y = data_x[train_ix], data_y[train_ix], data_x[test_ix], data_y[test_ix]\n",
    "\n",
    "        # Fit the classifier\n",
    "        classifier = RandomForestClassifier().fit(train_x, train_y)\n",
    "\n",
    "        # Predict the labels of the test set samples\n",
    "        predicted_labels = classifier.predict(test_x)\n",
    "\n",
    "        predicted_targets = np.append(predicted_targets, predicted_labels)\n",
    "        actual_targets = np.append(actual_targets, test_y)\n",
    "\n",
    "    return predicted_targets, actual_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(predicted_labels_list, y_test_list):\n",
    "    cnf_matrix = confusion_matrix(y_test_list, predicted_labels_list)\n",
    "    np.set_printoptions(precision=2)\n",
    "\n",
    "    # Plot non-normalized confusion matrix\n",
    "    plt.figure()\n",
    "    generate_confusion_matrix(cnf_matrix, classes=class_names, title='Confusion matrix, without normalization for RandomForest')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot normalized confusion matrix\n",
    "    plt.figure()\n",
    "    generate_confusion_matrix(cnf_matrix, classes=class_names, normalize=True, title='Normalized confusion matrix for RandomForest')\n",
    "    plt.savefig('./confusion.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_target, actual_target = evaluate_model(X.to_numpy(), y)\n",
    "plot_confusion_matrix(predicted_target, actual_target)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d43aaff7f63f8118a77db5d118aa75d2a0e830d35dd145dbb9c3b4b71a3a0ec0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
